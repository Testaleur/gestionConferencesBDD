{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e072b99b",
   "metadata": {},
   "source": [
    "##### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86f33458",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from faker import Faker\n",
    "import random\n",
    "\n",
    "database_filename = \"../gestionConferences.db\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049d72f8",
   "metadata": {},
   "source": [
    "##### Fill with random values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b05fc432",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = Faker()\n",
    "\n",
    "# --- Nombre d'entrées ---\n",
    "NB_PERSONNES = 100\n",
    "NB_UNIVERSITES = 5\n",
    "NB_CONFERENCES = 100\n",
    "NB_WORKSHOPS = 50\n",
    "NB_MIN_SOUMISSIONS_PAR_CONFERENCE = 1\n",
    "NB_MAX_SOUMISSIONS_PAR_CONFERENCE = 5\n",
    "NB_MIN_SESSIONS_PAR_CONFERENCE = 1\n",
    "NB_MAX_SESSIONS_PAR_CONFERENCE = 5\n",
    "NB_RESPONSABLES = 30\n",
    "NB_MIN_REPOS_PAR_CONF = 1\n",
    "NB_MAX_RESPO_PAR_CONF = 4\n",
    "NB_MIN_RESP_PAR_SESSION = 1\n",
    "NB_MAX_RESP_PAR_SESSION = 4\n",
    "NB_UTILISATEURS = 80\n",
    "\n",
    "# --- Connexion à la base ---\n",
    "conn = sqlite3.connect(database_filename)\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef7c6a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------\n",
    "# TABLE PERSONNE\n",
    "# ------------------------\n",
    "personnes_data = []\n",
    "for _ in range(NB_PERSONNES):\n",
    "    nom = fake.last_name()\n",
    "    prenom = fake.first_name()\n",
    "    # Create email based on first and last name\n",
    "    domain = random.choice([\"yahoo.fr\", \"university.edu\", \"mail.com\"])\n",
    "    mail = f\"{prenom.lower()}.{nom.lower()}@{domain}\"\n",
    "    personnes_data.append((nom, prenom, mail))\n",
    "\n",
    "cursor.executemany(\n",
    "    \"INSERT INTO personne (name, first_name, mail) VALUES (?, ?, ?);\",\n",
    "    personnes_data\n",
    ")\n",
    "\n",
    "# Récupérer les ids créés\n",
    "cursor.execute(\"SELECT id_personne FROM personne\")\n",
    "personnes_ids = [row[0] for row in cursor.fetchall()]\n",
    "\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f25b9147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------\n",
    "# TABLE UNIVERSITE\n",
    "# ------------------------\n",
    "university_names = [\"ECL\", \"Lyon-1\", \"Lyon-2\", \"Lyon-3\", \"Paris-Saclay\"]\n",
    "universites_data = []\n",
    "for i in range(NB_UNIVERSITES):\n",
    "    name = university_names[i]\n",
    "    adresse = fake.address()\n",
    "    domain_name = ''.join(e for e in name.lower() if e.isalnum())\n",
    "    mail = f\"contact@{domain_name}.edu\"\n",
    "    universites_data.append((name, adresse, mail))\n",
    "\n",
    "cursor.executemany(\n",
    "    \"INSERT INTO universite (name, adresse, mail) VALUES (?, ?, ?);\",\n",
    "    universites_data\n",
    ")\n",
    "\n",
    "cursor.execute(\"SELECT id_universite FROM universite\")\n",
    "universites_ids = [row[0] for row in cursor.fetchall()]\n",
    "\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c353f41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------\n",
    "# TABLE CONFERENCE\n",
    "# ------------------------\n",
    "from datetime import timedelta, date\n",
    "from utils.text_generation import generate_scientific_title, generate_scientific_intro\n",
    "faker_dict = {\n",
    "    \"France\": Faker(\"fr_FR\"),\n",
    "    \"Allemagne\": Faker(\"de_DE\"),\n",
    "    \"Espagne\": Faker(\"es_ES\")\n",
    "}\n",
    "countries = list(faker_dict.keys())\n",
    "weights = [0.8, 0.1, 0.1]\n",
    "\n",
    "editors_list = [\n",
    "    \"Springer\", \"Elsevier\", \"IEEE\", \"ACM\", \"Wiley\",\n",
    "    \"Taylor & Francis\", \"Nature\"\n",
    "]\n",
    "\n",
    "# --- Step 1: generate normal conferences (not workshops) ---\n",
    "normal_confs_data = []\n",
    "for _ in range(NB_CONFERENCES):\n",
    "    title = generate_scientific_title()\n",
    "    \n",
    "    # dates\n",
    "    year = random.choice([2025, 2026])\n",
    "    month = random.randint(1,12)\n",
    "    day = random.randint(1,28)\n",
    "    starting_date = date(year, month, day)\n",
    "    ending_date = starting_date + timedelta(days=random.randint(1,5))\n",
    "    \n",
    "    # location\n",
    "    country = random.choices(countries, weights=weights, k=1)[0]\n",
    "    fake = faker_dict[country]\n",
    "    city = fake.city()\n",
    "\n",
    "    series = random.choice([\"SDH\", \"CAISE\", \"TedTalk\", \"\"])\n",
    "    introduction = generate_scientific_intro()\n",
    "    type_conf = \"Conference\"\n",
    "    associated_conf = None\n",
    "    # Split title into words, lowercase and strip punctuation\n",
    "    words_in_title = [w.strip(\".,\").lower() for w in title.split()]\n",
    "\n",
    "    # Remove unwanted stopwords\n",
    "    stopwords = {\"in\", \"of\"}\n",
    "    filtered_words = [w for w in words_in_title if w not in stopwords]\n",
    "\n",
    "    # Select 1 to 4 keywords from the filtered list\n",
    "    n_keywords = min(len(filtered_words), random.randint(1, 4))\n",
    "    key_words = ','.join(random.sample(filtered_words, n_keywords))\n",
    "\n",
    "    editor = random.choice(editors_list)\n",
    "    id_universite = random.choice(universites_ids)\n",
    "    \n",
    "    normal_confs_data.append((\n",
    "        title, starting_date.isoformat(), ending_date.isoformat(),\n",
    "        city, country, series, introduction, type_conf,\n",
    "        associated_conf, key_words, editor, id_universite\n",
    "    ))\n",
    "\n",
    "# Insert normal conferences and get their IDs\n",
    "cursor.executemany(\n",
    "    \"\"\"INSERT INTO conference \n",
    "       (title, starting_date, ending_date, city, country, series, introduction,\n",
    "        type, associated_conf, key_words, editor, id_universite)\n",
    "       VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\"\"\",\n",
    "    normal_confs_data\n",
    ")\n",
    "conn.commit()\n",
    "\n",
    "cursor.execute(\"SELECT id_conference FROM conference WHERE type='Conference'\")\n",
    "normal_conf_ids = [row[0] for row in cursor.fetchall()]\n",
    "\n",
    "# --- Step 2: generate workshops ---\n",
    "workshops_data = []\n",
    "for _ in range(NB_WORKSHOPS):\n",
    "    title =  \"Workshop : \" + generate_scientific_title()\n",
    "\n",
    "    # dates\n",
    "    year = random.choice([2025, 2026])\n",
    "    month = random.randint(1,12)\n",
    "    day = random.randint(1,28)\n",
    "    starting_date = date(year, month, day)\n",
    "    ending_date = starting_date + timedelta(days=random.randint(1,5))\n",
    "    \n",
    "    # location\n",
    "    country = random.choices(countries, weights=weights, k=1)[0]\n",
    "    fake = faker_dict[country]\n",
    "    city = fake.city()\n",
    "    \n",
    "    series = random.choice([\"SDH\", \"CAISE\", \"TedTalk\", \"\"])\n",
    "    introduction = generate_scientific_intro()\n",
    "    type_conf = \"Workshop\"\n",
    "    # Choose associated_conf among existing normal conferences\n",
    "    associated_conf = random.choice(normal_conf_ids)\n",
    "    # Split title into words, lowercase and strip punctuation\n",
    "    words_in_title = [w.strip(\".,\").lower() for w in title.split()]\n",
    "\n",
    "    # Remove unwanted stopwords\n",
    "    stopwords = {\"in\", \"of\", \":\"}\n",
    "    filtered_words = [w for w in words_in_title if w not in stopwords]\n",
    "\n",
    "    # Select 1 to 4 keywords from the filtered list\n",
    "    n_keywords = min(len(filtered_words), random.randint(1, 4))\n",
    "    key_words = ','.join(random.sample(filtered_words, n_keywords))\n",
    "\n",
    "    editor = fake.name()\n",
    "    id_universite = random.choice(universites_ids)\n",
    "    \n",
    "    workshops_data.append((\n",
    "        title, starting_date.isoformat(), ending_date.isoformat(),\n",
    "        city, country, series, introduction, type_conf,\n",
    "        associated_conf, key_words, editor, id_universite\n",
    "    ))\n",
    "\n",
    "# Insert workshops\n",
    "cursor.executemany(\n",
    "    \"\"\"INSERT INTO conference \n",
    "       (title, starting_date, ending_date, city, country, series, introduction,\n",
    "        type, associated_conf, key_words, editor, id_universite)\n",
    "       VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\"\"\",\n",
    "    workshops_data\n",
    ")\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a46d4a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------\n",
    "# TABLE SOUMISSION\n",
    "# ------------------------\n",
    "cursor.execute(\"SELECT id_conference, type, starting_date FROM conference\")\n",
    "conferences = cursor.fetchall()  # [(id_conference, type, starting_date), ...]\n",
    "\n",
    "soumissions_data = []\n",
    "possible_soumissions_types = [\n",
    "    \"Regular paper\",\n",
    "    \"Panel\",\n",
    "    \"Tutorial\",\n",
    "    \"Industrial development\",\n",
    "    \"System descriptions\",\n",
    "    \"Poster\"\n",
    "]\n",
    "\n",
    "for conf_id, conf_type, conf_starting_date in conferences:\n",
    "    conf_start_date = date.fromisoformat(conf_starting_date)  # convert string to date\n",
    "\n",
    "    for _ in range(NB_MIN_SOUMISSIONS_PAR_CONFERENCE, NB_MAX_SOUMISSIONS_PAR_CONFERENCE):\n",
    "        category = random.choice(possible_soumissions_types)\n",
    "        if conf_type == \"Workshop\":\n",
    "            category = \"Workshop\"\n",
    "        \n",
    "        # page number\n",
    "        if category in [\"Regular paper\", \"Poster\", \"Industrial development\", \"System descriptions\"]:\n",
    "            pages_number = random.randint(1, 5)\n",
    "        else:\n",
    "            pages_number = None  # No page number for Tutorial, Panel, Workshop\n",
    "\n",
    "        # Layout\n",
    "        if conf_type == \"Workshop\":\n",
    "            layout = \"Workshop format\"\n",
    "        elif category in [\"Regular paper\", \"Panel\", \"Tutorial\", \"Poster\"]:\n",
    "            layout = f\"Font size {random.randint(8,10)}, Arial\"\n",
    "        else:\n",
    "            layout = random.choice([\"PPT\",\"PDF\",\"LaTeX\",\"Markdown\",\"Google Slides\"])\n",
    "\n",
    "        # Dates: must be before conference start\n",
    "        # Generate a random number of days before the conference (1–60)\n",
    "        days_before = random.randint(1, 60)\n",
    "        sending_date = conf_start_date - timedelta(days=random.randint(1, days_before))\n",
    "        notif_date = sending_date - timedelta(days=random.randint(1, 10))\n",
    "        deadline = notif_date - timedelta(days=random.randint(1, 10))\n",
    "\n",
    "        soumissions_data.append((category, pages_number, layout, deadline.isoformat(), notif_date.isoformat(), sending_date.isoformat(), conf_id))\n",
    "\n",
    "cursor.executemany(\n",
    "    \"\"\"INSERT INTO soumission\n",
    "       (category, pages_number, layout, deadline, notif_date, sending_date, id_conference)\n",
    "       VALUES (?, ?, ?, ?, ?, ?, ?)\"\"\",\n",
    "    soumissions_data\n",
    ")\n",
    "\n",
    "conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e28d71ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------\n",
    "# TABLE SESSION\n",
    "# ------------------------\n",
    "# First, fetch conference IDs and their key_words\n",
    "cursor.execute(\"SELECT id_conference, key_words, title FROM conference\")\n",
    "conferences = cursor.fetchall()  # [(id_conference, key_words, title), ...]\n",
    "\n",
    "sessions_data = []\n",
    "\n",
    "for conf_id, key_words_str, conf_title in conferences:\n",
    "    # Split the conference keywords into a list\n",
    "    conf_keywords = [kw.strip() for kw in key_words_str.split(',') if kw.strip()]\n",
    "    \n",
    "    for i in range(NB_MIN_SESSIONS_PAR_CONFERENCE, NB_MAX_SESSIONS_PAR_CONFERENCE):\n",
    "        title = f\"Session {i} : {conf_title}\"\n",
    "        # Choose 1 or 2 keywords from the conference keywords for the session themes\n",
    "        n_themes = min(len(conf_keywords), random.randint(1, 2))\n",
    "        themes = ','.join(random.sample(conf_keywords, n_themes)) if conf_keywords else ''\n",
    "        sessions_data.append((title, themes, conf_id))\n",
    "\n",
    "cursor.executemany(\n",
    "    \"INSERT INTO session (title, themes, id_conference) VALUES (?, ?, ?)\",\n",
    "    sessions_data\n",
    ")\n",
    "\n",
    "# Fetch session IDs if needed\n",
    "cursor.execute(\"SELECT id_session FROM session\")\n",
    "sessions_ids = [row[0] for row in cursor.fetchall()]\n",
    "\n",
    "conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4419a240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------\n",
    "# TABLE RESPONSABLE\n",
    "# ------------------------\n",
    "responsables_data = []\n",
    "responsable_types = [\n",
    "    \"Program Commitee chair\",\n",
    "    \"Steering Commitee \",\n",
    "    \"Poster chair\",\n",
    "    \"General chair\",\n",
    "    \"Industrial session chair\"\n",
    "]\n",
    "\n",
    "# Fetch personne info (id, name, first_name)\n",
    "cursor.execute(\"SELECT id_personne, name, first_name FROM personne\")\n",
    "personnes = cursor.fetchall()  # [(id_personne, name, first_name), ...]\n",
    "\n",
    "# Shuffle people to avoid duplicates\n",
    "random.shuffle(personnes)\n",
    "\n",
    "# Only take as many as NB_RESPONSABLES or the number of available people\n",
    "for id_personne, name, first_name in personnes[:NB_RESPONSABLES]:\n",
    "    # Professional email based on name\n",
    "    pro_adress = f\"{first_name.lower()}.{name.lower()}@work.com\"\n",
    "    \n",
    "    type_resp = random.choice(responsable_types)\n",
    "    responsables_data.append((pro_adress, type_resp, id_personne))\n",
    "\n",
    "cursor.executemany(\n",
    "    \"INSERT INTO responsable (pro_adress, type, id_personne) VALUES (?, ?, ?)\",\n",
    "    responsables_data\n",
    ")\n",
    "\n",
    "cursor.execute(\"SELECT id_responsable FROM responsable\")\n",
    "responsables_ids = [row[0] for row in cursor.fetchall()]\n",
    "\n",
    "conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f25da098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------\n",
    "# TABLE DIRECTION\n",
    "# ------------------------\n",
    "direction_data = []\n",
    "\n",
    "# Keep track of existing pairs to avoid duplicates\n",
    "existing_pairs = set()\n",
    "\n",
    "cursor.execute(\"SELECT id_conference FROM conference\")\n",
    "conferences_ids = [row[0] for row in cursor.fetchall()]\n",
    "\n",
    "for conf_id in conferences_ids:\n",
    "    resp_sample = random.sample(responsables_ids, k=random.randint(NB_MIN_REPOS_PAR_CONF, NB_MAX_RESPO_PAR_CONF))\n",
    "    for resp_id in resp_sample:\n",
    "        pair = (conf_id, resp_id)\n",
    "        if pair not in existing_pairs:\n",
    "            direction_data.append(pair)\n",
    "            existing_pairs.add(pair)  # mark as used\n",
    "\n",
    "cursor.executemany(\n",
    "    \"INSERT INTO direction (id_conference, id_responsable) VALUES (?, ?)\",\n",
    "    direction_data\n",
    ")\n",
    "\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4412f597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------\n",
    "# TABLE EVALUATION\n",
    "# ------------------------\n",
    "evaluation_data = []\n",
    "\n",
    "# Track existing (session, responsable) pairs to avoid duplicates\n",
    "existing_pairs = set()\n",
    "\n",
    "for session_id in sessions_ids:\n",
    "    # Ensure each session has at least one responsable\n",
    "    # Pick responsables randomly\n",
    "    n_responsables = random.randint(NB_MIN_RESP_PAR_SESSION, NB_MAX_RESP_PAR_SESSION)\n",
    "    resp_sample = random.sample(responsables_ids, k=n_responsables)\n",
    "    \n",
    "    for resp_id in resp_sample:\n",
    "        pair = (session_id, resp_id)\n",
    "        if pair not in existing_pairs:\n",
    "            evaluation_data.append(pair)\n",
    "            existing_pairs.add(pair)\n",
    "\n",
    "# Optional: you could add more random assignments later, but each session already has >=1 responsable\n",
    "\n",
    "cursor.executemany(\n",
    "    \"INSERT INTO evaluation (id_session, id_responsable) VALUES (?, ?)\",\n",
    "    evaluation_data\n",
    ")\n",
    "\n",
    "conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0f3368d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------\n",
    "# TABLE UTILISATEUR\n",
    "# ------------------------\n",
    "\n",
    "utilisateurs_data = []\n",
    "\n",
    "# Fetch all personnes IDs\n",
    "cursor.execute(\"SELECT id_personne FROM personne\")\n",
    "personnes = [row[0] for row in cursor.fetchall()]\n",
    "\n",
    "# Shuffle to ensure uniqueness\n",
    "random.shuffle(personnes)\n",
    "\n",
    "# Fetch all conference keywords\n",
    "cursor.execute(\"SELECT key_words FROM conference\")\n",
    "all_conf_keywords = [\n",
    "  \"Neural Networks\",\n",
    "  \"Quantum Computing\",\n",
    "  \"Machine Learning\",\n",
    "  \"Cybersecurity\",\n",
    "  \"Data Mining\",\n",
    "  \"Bioinformatics\",\n",
    "  \"Robotics\",\n",
    "  \"Climate Modeling\",\n",
    "  \"Artificial Intelligence\",\n",
    "  \"Software Engineering\"\n",
    "]\n",
    "\n",
    "# Limit number of utilisateurs to number of available personnes\n",
    "nb_to_create = min(NB_UTILISATEURS, len(personnes))\n",
    "\n",
    "for id_personne in personnes[:nb_to_create]:\n",
    "    # Choose 1-3 keywords as profile\n",
    "    n_keywords = random.randint(1, min(3, len(all_conf_keywords)))\n",
    "    profile_keywords = random.sample(all_conf_keywords, n_keywords)\n",
    "    profile = ','.join(profile_keywords)\n",
    "    \n",
    "    utilisateurs_data.append((profile, id_personne))\n",
    "\n",
    "cursor.executemany(\n",
    "    \"INSERT INTO utilisateur (profile, id_personne) VALUES (?, ?)\",\n",
    "    utilisateurs_data\n",
    ")\n",
    "\n",
    "conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e6f21e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
